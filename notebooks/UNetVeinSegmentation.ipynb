{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, pdb, random, time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import torch\n",
    "import torchinfo\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append('../')  \n",
    "import utils.ImageLoader as ImageLoader\n",
    "import utils.UNetTileGenerator as UNetTileGenerator\n",
    "from utils.GetLowestGPU import GetLowestGPU\n",
    "import utils.ModelWrapperGenerator as MW\n",
    "import models.BuildUNet as BuildUNet\n",
    "\n",
    "if 'device' not in locals():\n",
    "    device = torch.device(GetLowestGPU([0], verbose=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# options\n",
    "image_path = '../data/images/'\n",
    "mask_path = '../data/vein_masks/'\n",
    "roi_path = '../data/leaf_preds/'\n",
    "image_extension = '.jpeg'\n",
    "mask_extension = '.png'\n",
    "roi_extension = '.png'\n",
    "window_size = 128\n",
    "verbose=True\n",
    "plot = True\n",
    "figsize = 5\n",
    "\n",
    "# initialize loader\n",
    "reload(ImageLoader)\n",
    "IL = ImageLoader.ImageLoader(\n",
    "    image_path=image_path, \n",
    "    mask_path=mask_path,  \n",
    "    roi_path=roi_path,\n",
    "    image_ext=image_extension,\n",
    "    mask_ext=mask_extension,\n",
    "    roi_ext=roi_extension,\n",
    "    window_size=window_size, \n",
    "    verbose=verbose)\n",
    "\n",
    "# load data\n",
    "print('Loading data...'); time.sleep(0.3)\n",
    "images, masks, rois = IL.load_data()\n",
    "file_names = IL.file_names\n",
    "\n",
    "# add mask to roi to include petiole\n",
    "rois = [(rois[i]+masks[i]).clip(0, 1) for i in range(len(rois))]\n",
    "\n",
    "# plot\n",
    "if plot:\n",
    "    print('Plotting examples...')\n",
    "    size = [images[0].shape[0], images[0].shape[1]]\n",
    "    fig = plt.figure(figsize=(6*size[1]/size[0]*figsize, np.ceil(len(IL)/2)*figsize))\n",
    "    for i in range(len(IL)):\n",
    "        ax = fig.add_subplot(int(np.ceil(len(IL)/2)), 6, 3*i+1)\n",
    "        plt.imshow(images[i], aspect='auto')\n",
    "        ax = fig.add_subplot(int(np.ceil(len(IL)/2)), 6, 3*i+2)\n",
    "        plt.imshow(masks[i], aspect='auto', cmap='gray')\n",
    "        plt.title(file_names[i] + ', index = {0}'.format(i))\n",
    "        ax = fig.add_subplot(int(np.ceil(len(IL)/2)), 6, 3*i+3)\n",
    "        plt.imshow(rois[i], aspect='auto', cmap='gray')\n",
    "    plt.tight_layout(pad=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# options\n",
    "val_img_idx = [file_names.index(l) for l in ['C_1_14_18_bot.png', 'C_1_8_1_bot.png']]\n",
    "dilate = 50\n",
    "plot = True\n",
    "verbose = True\n",
    "\n",
    "# instantiate data loaders\n",
    "reload(UNetTileGenerator)\n",
    "train_dataset = UNetTileGenerator.UNetTileGenerator(\n",
    "    images=[images[i] for i in range(len(images)) if i not in val_img_idx], \n",
    "    masks=[masks[i] for i in range(len(masks)) if i not in val_img_idx], \n",
    "    rois=[rois[i] for i in range(len(rois)) if i not in val_img_idx], \n",
    "    window_size=window_size, \n",
    "    n_samples=None, # 7_000_000 250_000\n",
    "    augment=True,\n",
    "    dilate=dilate)\n",
    "val_dataset = UNetTileGenerator.UNetTileGenerator(\n",
    "    images=[images[i] for i in range(len(images)) if i in val_img_idx], \n",
    "    masks=[masks[i] for i in range(len(masks)) if i in val_img_idx], \n",
    "    rois=[rois[i] for i in range(len(rois)) if i in val_img_idx], \n",
    "    window_size=window_size, \n",
    "    n_samples=None, # 2_500_000 50_000\n",
    "    augment=False,\n",
    "    dilate=dilate)\n",
    "print('Train: {0:,}, Val: {1:,}'.format(len(train_dataset), len(val_dataset)))\n",
    "print()\n",
    "\n",
    "# plot example input/output tiles\n",
    "if plot:\n",
    "    print('Plotting training examples...')\n",
    "    w = int(window_size/2/2)\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    N = len(train_dataset)\n",
    "    for i in range(64):\n",
    "        rand_idx = np.random.choice(N)\n",
    "        tile, mask = train_dataset[rand_idx]\n",
    "        tile = train_dataset.image2numpy(tile)\n",
    "        mask = train_dataset.mask2numpy(mask)\n",
    "        tile[mask==1] = [1, 0, 0]\n",
    "        ax = fig.add_subplot(8, 8, i+1)\n",
    "        ax.imshow(tile, aspect='auto')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout(pad=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train leaf tracing CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# options\n",
    "layers = [32, 32, 32, 32, 64, 128]\n",
    "loss = 'bce' # 'fl' 'bce'\n",
    "save_name = f'vein_unet_{loss}_{window_size}'\n",
    "\n",
    "# initialize model and optimizer\n",
    "reload(BuildUNet)\n",
    "unet = BuildUNet.BuildUNet(\n",
    "    layers=layers,\n",
    "    input_channels=3,\n",
    "    output_channels=1,\n",
    "    hidden_activation=torch.nn.LeakyReLU(),\n",
    "    output_activation=torch.nn.Sigmoid(),\n",
    "    dropout_rate=0.0,\n",
    "    num_convs=3,\n",
    ").to(device)\n",
    "opt = torch.optim.Adam(unet.parameters(), lr=1e-3)\n",
    "\n",
    "# focal loss\n",
    "gamma, alpha = 2.0, 0.25\n",
    "def FocalLoss(pred, target):\n",
    "    pred = pred.clamp(min=1e-7, max=1.0-1e-7)\n",
    "    pt_1 = torch.where(target == 1, pred, torch.ones_like(pred))\n",
    "    pt_0 = torch.where(target == 0, pred, torch.zeros_like(pred))\n",
    "    out = -torch.mean(alpha*((1.0 - pt_1)**gamma)*torch.log(pt_1))\n",
    "    out = out - torch.mean((1.0 - alpha)*(pt_0**gamma)*torch.log(1.0 - pt_0))\n",
    "    return out\n",
    "\n",
    "# wrap model\n",
    "reload(MW)\n",
    "model = MW.ModelWrapper(\n",
    "    model=unet,\n",
    "    optimizer=opt,\n",
    "    loss=FocalLoss if loss == 'fl' else torch.nn.BCELoss(),\n",
    "    save_name=f'../weights/{save_name}',\n",
    "    log_name=f'../logs/{save_name}.txt',\n",
    "    device=device)\n",
    "\n",
    "# model summary\n",
    "torchinfo.summary(\n",
    "    unet, \n",
    "    input_size=(1, 3, window_size, window_size), \n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# options\n",
    "epochs = 1000\n",
    "batch_size = 512\n",
    "workers = 128\n",
    "early_stopping = 20\n",
    "\n",
    "# train \n",
    "model.fit(\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    early_stopping=early_stopping,\n",
    "    verbose=2,\n",
    "    workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rel_save_thresh = 0.0\n",
    "\n",
    "# load errors\n",
    "total_train_losses, total_val_losses = [], []\n",
    "with open(model.log_name, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        line = line.split(',')\n",
    "        total_train_losses.append(float(line[1]))\n",
    "        total_val_losses.append(float(line[2]))\n",
    "\n",
    "# find where errors decreased\n",
    "train_idx, train_loss, val_idx, val_loss = [], [], [], []\n",
    "best_train, best_val = 1e12, 1e12\n",
    "for i in range(len(total_train_losses)):\n",
    "    rel_diff = (best_train - total_train_losses[i])\n",
    "    rel_diff /= best_train\n",
    "    if rel_diff > rel_save_thresh:\n",
    "        best_train = total_train_losses[i]\n",
    "        train_idx.append(i)\n",
    "        train_loss.append(best_train)\n",
    "    rel_diff = (best_val - total_val_losses[i])\n",
    "    rel_diff /= best_val\n",
    "    if rel_diff > rel_save_thresh:\n",
    "        best_val = total_val_losses[i]\n",
    "        val_idx.append(i)\n",
    "        val_loss.append(best_val)\n",
    "idx = np.argmin(val_loss)\n",
    "\n",
    "# plot errors and improvements\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(total_train_losses, 'b')\n",
    "plt.plot(total_val_losses, 'r')\n",
    "plt.plot(val_idx[idx], val_loss[idx], 'ko')\n",
    "plt.legend([r'Train error', r'Val error', 'Best model'])\n",
    "plt.xlabel(r'Epochs')\n",
    "plt.ylabel(r'Total Loss')\n",
    "plt.title(r'Convergence')\n",
    "plt.grid()\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(train_idx, train_loss, 'b.-')\n",
    "plt.plot(val_idx, val_loss, 'r.-')\n",
    "plt.legend([r'Train error', r'Val error'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(r'Total Loss')\n",
    "plt.title(r'Improvements')\n",
    "plt.grid()\n",
    "plt.tight_layout(h_pad=2, w_pad=2)\n",
    "plt.show()\n",
    "\n",
    "# plot log-scaled errors and improvements\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.semilogy(total_train_losses, 'b')\n",
    "plt.semilogy(total_val_losses, 'r')\n",
    "plt.semilogy(val_idx[idx], val_loss[idx], 'ko')\n",
    "plt.legend([r'Train error', r'Val error', 'Best model'])\n",
    "plt.xlabel(r'Epochs')\n",
    "plt.ylabel(r'Total Loss')\n",
    "plt.title(r'Log Convergence')\n",
    "plt.grid()\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.semilogy(train_idx, train_loss, 'b.-')\n",
    "plt.semilogy(val_idx, val_loss, 'r.-')\n",
    "plt.legend([r'Train error', r'Val error'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(r'Total Loss')\n",
    "plt.title(r'Log Improvements')\n",
    "plt.grid()\n",
    "plt.tight_layout(h_pad=2, w_pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model weights\n",
    "model.load_best_val(device=device)\n",
    "\n",
    "# plot example inputs/outputs/predictions\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "for i in range(64):\n",
    "    \n",
    "    # predict on random validation tile\n",
    "    rand_idx = np.random.choice(len(val_dataset))\n",
    "    tile, true = val_dataset[rand_idx]\n",
    "    pred = model.predict(tile[None].to(device))[0]\n",
    "    tile = val_dataset.image2numpy(tile)\n",
    "    true = val_dataset.mask2numpy(true)\n",
    "    pred = val_dataset.mask2numpy(pred) > 0.5\n",
    "    \n",
    "    tile[pred] = [1, 0, 0]\n",
    "    \n",
    "    # plot tile, ground truth, and prediction\n",
    "    ax = fig.add_subplot(8, 8, i+1)\n",
    "    plt.imshow(tile, aspect='auto')\n",
    "    plt.axis('off')\n",
    "    plt.xlim([0, window_size])\n",
    "    plt.ylim([0, window_size])\n",
    "    \n",
    "plt.tight_layout(pad=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# options\n",
    "loss = 'bce' # 'bce', 'fl'\n",
    "image_path = '../data/images/'\n",
    "roi_path = '../data/leaf_unet_preds/'\n",
    "pred_path = f'../data/vein_unet_{loss}_preds/'\n",
    "prob_path = f'../data/vein_unet_{loss}_probs/'\n",
    "image_extension = 'jpeg'\n",
    "roi_extension = 'png'\n",
    "pred_extension = 'png'\n",
    "max_number = 10 # number of images to segment, set to None for all images\n",
    "verbose = True\n",
    "save = False\n",
    "show = True\n",
    "fig_size = 15\n",
    "\n",
    "# book keeping\n",
    "w = int(window_size/2)\n",
    "\n",
    "# get image paths\n",
    "image_names = [os.path.basename(f) for f in glob.glob(image_path + '*' + image_extension)]\n",
    "image_names = [i for i in image_names if '_bot' in i]\n",
    "image_names.sort()\n",
    "\n",
    "# load model weights\n",
    "model.save_name = f'../weights/vein_unet_{loss}_{window_size}'\n",
    "model.log_name = f'../logs/vein_unet_{loss}_{window_size}.txt'\n",
    "model.load_best_val(device=device)\n",
    "\n",
    "# loop over all leaf images\n",
    "for image_idx, image_name in enumerate(tqdm(image_names)):\n",
    "    \n",
    "    # don't exceed maximum\n",
    "    if max_number is not None:\n",
    "        if image_idx >= max_number:\n",
    "            break\n",
    "            \n",
    "    # load image\n",
    "    if verbose:\n",
    "        print(f'Loading {image_name}...')\n",
    "    image = np.array(Image.open(image_path + image_name)) / 255\n",
    "    roi = np.array(Image.open(roi_path + image_name.replace('jpeg', 'png')))\n",
    "    roi = (roi[:, :, 0] / 255) > 0.5\n",
    "    \n",
    "    # start timer\n",
    "    t0 = time.time()\n",
    "\n",
    "    # pad image\n",
    "    image = np.pad(image, ((w, w), (w, w), (0, 0)), 'constant', constant_values=1)\n",
    "    roi = np.pad(roi, ((w, w), (w, w)), 'constant', constant_values=0)\n",
    "\n",
    "    # initialize mask\n",
    "    prob = np.zeros_like(image[:, :, 0])\n",
    "    counts = np.zeros_like(image[:, :, 0])\n",
    "    \n",
    "    # progress bar\n",
    "    if verbose:\n",
    "        ii = len(range(w, image.shape[0] - w, w))\n",
    "        jj = len(range(w, image.shape[1] - w, w))\n",
    "        pbar = tqdm(total=ii*jj)\n",
    "\n",
    "    # loop through image in window_size/2 steps\n",
    "    for i in range(w, image.shape[0] - w, w):\n",
    "        for j in range(w, image.shape[1] - w, w):\n",
    "\n",
    "            # get window\n",
    "            tile = image[i-w:i+w, j-w:j+w, :]\n",
    "            tile = torch.from_numpy(tile).permute(2, 0, 1).float().to(device)\n",
    "\n",
    "            # predict\n",
    "            pred = model.predict(tile[None])[0]\n",
    "            pred = pred.cpu().detach().numpy()[0] > 0.5\n",
    "            pred = pred.astype(float)\n",
    "\n",
    "            # add to mask\n",
    "            prob[i-w:i+w, j-w:j+w] += pred\n",
    "            counts[i-w:i+w, j-w:j+w] += 1\n",
    "            \n",
    "            # update progress bar\n",
    "            if verbose:\n",
    "                pbar.update(1)\n",
    "\n",
    "    # average probabilities\n",
    "    prob = prob / counts.clip(min=1)\n",
    "\n",
    "    # threshold probabilities for venation mask\n",
    "    if verbose:\n",
    "        print('Computing optimal threshold...')\n",
    "    try:\n",
    "        thresholds = np.linspace(0.1, 0.9, 101)\n",
    "        structure = ndimage.generate_binary_structure(2,2)\n",
    "        n_objects, sizes = np.array(\n",
    "            [[ndimage.label(prob>t, structure=structure)[1], (prob>t).sum()] for t in thresholds]).T\n",
    "        peaks, _ = find_peaks(-n_objects/sizes, prominence=100/sizes.max(), distance=10)\n",
    "        threshold = thresholds[peaks[0]]\n",
    "    except:\n",
    "        threshold = 0.5\n",
    "    mask = 1.0*np.array(prob > threshold)\n",
    "    \n",
    "    # remove background artifacts\n",
    "    leaf, petiole = mask.copy(), mask.copy()\n",
    "    leaf[~roi], petiole[roi] = 0, 0\n",
    "    petiole = measure.label(petiole)\n",
    "    petiole = petiole == np.argmax(np.bincount(petiole.flat)[1:]) + 1\n",
    "    mask = leaf + petiole\n",
    "\n",
    "    # remove padding\n",
    "    image = image[w:-w, w:-w, :]\n",
    "    mask = mask[w:-w, w:-w]\n",
    "    prob = prob[w:-w, w:-w]\n",
    "    \n",
    "    # end timer\n",
    "    t1 = time.time()\n",
    "    if verbose:\n",
    "        print(f'Finished in {t1-t0:.2f} seconds.')\n",
    "\n",
    "    # save results\n",
    "    if save:\n",
    "        \n",
    "        if verbose: \n",
    "            print('Saving mask...')\n",
    "        save_mask = np.concatenate([mask[:,:,None], mask[:,:,None], mask[:,:,None]], axis=-1)\n",
    "        pil_mask = Image.fromarray(np.uint8(255*save_mask))\n",
    "        name = pred_path + image_name.replace(image_extension, pred_extension)\n",
    "        pil_mask.save(name, quality=100, subsampling=0)\n",
    "        \n",
    "        if verbose: \n",
    "            print('Saving prob...')\n",
    "        save_prob = np.concatenate([prob[:,:,None], prob[:,:,None], prob[:,:,None]], axis=-1)\n",
    "        pil_prob = Image.fromarray(np.uint8(255*save_prob))\n",
    "        name = prob_path + image_name.replace(image_extension, pred_extension)\n",
    "        pil_prob.save(name, quality=100, subsampling=0)\n",
    "\n",
    "    # plot overlay\n",
    "    if show:\n",
    "        if max_number is None and image_idx % 100 != 0:\n",
    "            continue\n",
    "        if verbose: \n",
    "            print('Plotting overlay...')\n",
    "        fig = plt.figure(figsize=(image.shape[1]/image.shape[0]*fig_size, fig_size))\n",
    "        plot_image = image.copy()\n",
    "        plot_image[mask==1] = [1, 0, 0]\n",
    "        plt.imshow(plot_image)\n",
    "        plt.show()\n",
    "        \n",
    "    if verbose: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
