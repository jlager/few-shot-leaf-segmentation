{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "drawn-workstation",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cpu\n"
     ]
    }
   ],
   "source": [
    "import os, sys, glob, pdb, random, time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "from importlib import reload\n",
    "from skimage import measure\n",
    "\n",
    "sys.path.append('../')\n",
    "import models.BuildCNN as BuildCNN\n",
    "import models.VeinGrower as VeinGrower\n",
    "from utils.GetLowestGPU import GetLowestGPU\n",
    "\n",
    "if 'device' not in locals():\n",
    "    device = torch.device(GetLowestGPU(verbose=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-speech",
   "metadata": {},
   "source": [
    "# Initialize grower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "affiliated-search",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cnn model...\n",
      "initializing vein grower...\n"
     ]
    }
   ],
   "source": [
    "# options\n",
    "window_size = 128\n",
    "weights_path = f'../weights/vein_grower_{window_size}_best_val_model.save'\n",
    "layers = layers = [3, 32, 32, 32, 32, 64, 128]\n",
    "output_shape = [2, 3, 3]\n",
    "output_activation = torch.nn.Softmax2d()\n",
    "\n",
    "# load CNN model\n",
    "print('loading cnn model...')\n",
    "reload(BuildCNN)\n",
    "model = BuildCNN.CNN(\n",
    "    window_size=window_size, \n",
    "    layers=layers,\n",
    "    output_shape=output_shape,\n",
    "    output_activation=output_activation).to(device)\n",
    "weights = torch.load(weights_path, map_location=device)\n",
    "model.load_state_dict(weights)\n",
    "model.eval()\n",
    "\n",
    "# initialize vein grower\n",
    "print('initializing vein grower...')\n",
    "reload(VeinGrower)\n",
    "grower = VeinGrower.VeinGrower(\n",
    "    window_size=window_size, \n",
    "    model=model,\n",
    "    device=device, \n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc217957-5207-4f7d-8957-fa14b8d608cb",
   "metadata": {},
   "source": [
    "# Grower inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9faef5d-e70c-431a-b8bb-eb844a219d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C_1_10_10_bot.jpeg...\n",
      "Iteration 3 | Samples = 19480           "
     ]
    }
   ],
   "source": [
    "# options\n",
    "image_path = '../data/images/'\n",
    "roi_path = '../data/leaf_preds/'\n",
    "pred_path = '../data/vein_preds/'\n",
    "prob_path = '../data/vein_probs/'\n",
    "image_extension = 'jpeg'\n",
    "roi_extension = 'png'\n",
    "pred_extension = 'png'\n",
    "prob_extension = 'png'\n",
    "n_locs = 10000 # number of seed pixels\n",
    "batch_size = 1024\n",
    "threshold = None\n",
    "post_process = True\n",
    "max_number = 10 # number of images to segment, set to None for all images\n",
    "verbose = True\n",
    "save = False\n",
    "show = True\n",
    "fig_size = 15\n",
    "\n",
    "# get image paths\n",
    "image_names = [os.path.basename(f) for f in glob.glob(image_path+'*'+image_extension) if '_bot' in f]\n",
    "image_names.sort()\n",
    "\n",
    "# loop over all leaf images\n",
    "for image_idx, image_name in enumerate(image_names):\n",
    "    \n",
    "    # don't exceed maximum\n",
    "    if max_number is not None:\n",
    "        if image_idx >= max_number:\n",
    "            break\n",
    "            \n",
    "    # load image\n",
    "    if verbose:\n",
    "        print(f'Loading {image_name}...')\n",
    "    image = np.array(Image.open(image_path + image_name), dtype=np.float32)/255\n",
    "    if roi_path is not None:\n",
    "        roi = np.array(Image.open(\n",
    "            roi_path + image_name.replace(image_extension, roi_extension)), dtype=np.float32)/255\n",
    "        roi = roi[:,:,0] > 0.5\n",
    "    else:\n",
    "        roi = None\n",
    "    \n",
    "    # segment the venation\n",
    "    t0 = time.time()\n",
    "    prob, mask = grower.grow(\n",
    "        image=image, \n",
    "        roi=roi, \n",
    "        start_locs=None, \n",
    "        n_locs=n_locs, \n",
    "        batch_size=batch_size, \n",
    "        threshold=threshold,\n",
    "        post_process=post_process)\n",
    "    t1 = time.time()\n",
    "    if verbose:\n",
    "        print('Iteration completed in {0:1.2f} seconds'.format(t1-t0))\n",
    "\n",
    "    # remove padding\n",
    "    image = image[\n",
    "        int(window_size/2):-int(window_size/2), \n",
    "        int(window_size/2):-int(window_size/2)]\n",
    "    mask = mask[\n",
    "        int(window_size/2):-int(window_size/2), \n",
    "        int(window_size/2):-int(window_size/2)]\n",
    "    prob = prob[\n",
    "        int(window_size/2):-int(window_size/2), \n",
    "        int(window_size/2):-int(window_size/2)]\n",
    "\n",
    "    # save mask\n",
    "    if save:\n",
    "        if verbose: \n",
    "            print('Saving mask...')\n",
    "        save_mask = np.concatenate([mask[:,:,None], mask[:,:,None], mask[:,:,None]], axis=-1)\n",
    "        pil_mask = Image.fromarray(np.uint8(255*save_mask))\n",
    "        name = pred_path + image_name.replace(image_extension, pred_extension)\n",
    "        pil_mask.save(name, quality=100, subsampling=0)\n",
    "\n",
    "    # save prob\n",
    "    if save:\n",
    "        if verbose: \n",
    "            print('Saving prob...')\n",
    "        save_prob = np.concatenate([prob[:,:,None], prob[:,:,None], prob[:,:,None]], axis=-1)\n",
    "        pil_prob = Image.fromarray(np.uint8(255*save_prob))\n",
    "        name = prob_path + image_name.replace(image_extension, prob_extension)\n",
    "        pil_prob.save(name, quality=100, subsampling=0)\n",
    "\n",
    "    # plot overlay\n",
    "    if show:\n",
    "        if verbose: \n",
    "            print('Plotting overlay...')\n",
    "        image[mask] = [1, 0, 0]\n",
    "        fig = plt.figure(figsize=(image.shape[1]/image.shape[0]*fig_size, fig_size))\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "        \n",
    "    if verbose: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4953e86-8afb-4472-aea0-e9bb6e069024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7091072-0fbd-434e-901c-592cbc97c88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ca37d-2a61-4e59-999f-e5290148b366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
