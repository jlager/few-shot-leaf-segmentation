{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys, glob, pdb, random, time\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "import torch\n",
    "import torchinfo\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append('../')\n",
    "import utils.ImageLoader as ImageLoader\n",
    "import utils.UNetTileGenerator as UNetTileGenerator\n",
    "from utils.GetLowestGPU import GetLowestGPU\n",
    "import utils.ModelWrapperGenerator as MW\n",
    "import models.BuildUNet as BuildUNet\n",
    "\n",
    "if 'device' not in locals():\n",
    "    device = torch.device(GetLowestGPU(verbose=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# options\n",
    "image_path = '../data/images/'\n",
    "mask_path = '../data/leaf_masks/'\n",
    "image_extension = '.jpeg'\n",
    "mask_extension = '.png'\n",
    "window_size = 256\n",
    "pad = True\n",
    "verbose=True\n",
    "plot = True\n",
    "figsize = 5\n",
    "\n",
    "# initialize loader\n",
    "reload(ImageLoader)\n",
    "IL = ImageLoader.ImageLoader(\n",
    "    image_path=image_path, \n",
    "    mask_path=mask_path,  \n",
    "    image_ext=image_extension,\n",
    "    mask_ext=mask_extension,\n",
    "    window_size=window_size, \n",
    "    pad=pad,\n",
    "    verbose=verbose)\n",
    "\n",
    "# load data\n",
    "print('Loading data...'); time.sleep(0.3)\n",
    "images, masks = IL.load_data()\n",
    "file_names = IL.file_names\n",
    "\n",
    "# plot\n",
    "if plot:\n",
    "    print('Plotting examples...')\n",
    "    size = [images[0].shape[0], images[0].shape[1]]\n",
    "    n_rows = min(np.ceil(len(IL)/2), 8)\n",
    "    fig = plt.figure(figsize=(4*size[1]/size[0]*figsize, n_rows*figsize))\n",
    "    for i in range(min(len(IL), 8)):\n",
    "        ax = fig.add_subplot(n_rows, 4, 2*i+1)\n",
    "        plt.imshow(images[i], aspect='auto')\n",
    "        plt.title(file_names[i])\n",
    "        ax = fig.add_subplot(n_rows, 4, 2*i+2)\n",
    "        plt.imshow(masks[i], aspect='auto', cmap='gray')\n",
    "        plt.title('index = {0}'.format(i))\n",
    "    plt.tight_layout(pad=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# options\n",
    "plot = True\n",
    "verbose = True\n",
    "\n",
    "# split images into train/val sets\n",
    "val_img_idx = [8, 7, 19, 13, 16, 41, 26, 21, 36, 12]\n",
    "train_img_idx = [i for i in range(len(masks)) if i not in val_img_idx]\n",
    "print('Val index: {0}'.format(val_img_idx))\n",
    "print()\n",
    "\n",
    "# instantiate data loaders\n",
    "reload(UNetTileGenerator)\n",
    "train_dataset = UNetTileGenerator.UNetTileGenerator(\n",
    "    images=[images[i] for i in train_img_idx], \n",
    "    masks=[masks[i] for i in train_img_idx], \n",
    "    window_size=window_size, \n",
    "    n_samples=250_000,\n",
    "    augment=True,\n",
    "    dilate=window_size,\n",
    "    verbose=verbose)\n",
    "val_dataset = UNetTileGenerator.UNetTileGenerator(\n",
    "    images=[images[i] for i in val_img_idx], \n",
    "    masks=[masks[i] for i in val_img_idx], \n",
    "    window_size=window_size, \n",
    "    n_samples=50_000, \n",
    "    augment=False, \n",
    "    dilate=window_size, \n",
    "    verbose=verbose)\n",
    "print('Train: {0:,}, Val: {1:,}'.format(len(train_dataset), len(val_dataset)))\n",
    "print()\n",
    "\n",
    "# plot example input/output tiles\n",
    "if plot:\n",
    "    print('Plotting training examples...')\n",
    "    w = int(window_size/2/2)\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    N = len(train_dataset)\n",
    "    for i in range(64):\n",
    "        rand_idx = np.random.choice(N)\n",
    "        tile, mask = train_dataset[rand_idx]\n",
    "        tile = train_dataset.image2numpy(tile)\n",
    "        mask = train_dataset.mask2numpy(mask)\n",
    "        mask[0], mask[-1], mask[:,0], mask[:,-1] = 0, 0, 0, 0\n",
    "        ax = fig.add_subplot(8, 8, i+1)\n",
    "        ax.imshow(tile, aspect='auto')\n",
    "        if mask.sum() > 0:\n",
    "            contour = measure.find_contours(mask, 0.5)[0]\n",
    "            ax.plot(contour[:, 1], contour[:, 0], linewidth=2, color='r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout(pad=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train leaf segmentation U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# options\n",
    "layers = [32, 32, 32, 32, 32, 64, 128]\n",
    "save_name = f'leaf_unet_{window_size}'\n",
    "\n",
    "# initialize model and optimizer\n",
    "reload(BuildUNet)\n",
    "unet = BuildUNet.BuildUNet(\n",
    "    layers=layers,\n",
    "    input_channels=3,\n",
    "    output_channels=1,\n",
    "    hidden_activation=torch.nn.LeakyReLU(),\n",
    "    output_activation=torch.nn.Sigmoid(),\n",
    "    dropout_rate=0.0,\n",
    "    num_convs=3,\n",
    ").to(device)\n",
    "opt = torch.optim.Adam(unet.parameters(), lr=1e-3)\n",
    "\n",
    "# wrap model\n",
    "reload(MW)\n",
    "model = MW.ModelWrapper(\n",
    "    model=unet,\n",
    "    optimizer=opt,\n",
    "    loss=torch.nn.BCELoss(),\n",
    "    save_name=f'../weights/{save_name}',\n",
    "    log_name=f'../logs/{save_name}.txt',\n",
    "    device=device)\n",
    "\n",
    "# model summary\n",
    "torchinfo.summary(\n",
    "    unet, \n",
    "    input_size=(1, 3, window_size, window_size), \n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# options\n",
    "epochs = 1000\n",
    "batch_size = 128\n",
    "workers = 64\n",
    "early_stopping = 20\n",
    "\n",
    "# train \n",
    "model.fit(\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    early_stopping=early_stopping,\n",
    "    verbose=2,\n",
    "    workers=workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rel_save_thresh = 0.0\n",
    "\n",
    "# load errors\n",
    "total_train_losses, total_val_losses = [], []\n",
    "with open(model.log_name, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        line = line.split(',')\n",
    "        total_train_losses.append(float(line[1]))\n",
    "        total_val_losses.append(float(line[2]))\n",
    "\n",
    "# find where errors decreased\n",
    "train_idx, train_loss, val_idx, val_loss = [], [], [], []\n",
    "best_train, best_val = 1e12, 1e12\n",
    "for i in range(len(total_train_losses)):\n",
    "    rel_diff = (best_train - total_train_losses[i])\n",
    "    rel_diff /= best_train\n",
    "    if rel_diff > rel_save_thresh:\n",
    "        best_train = total_train_losses[i]\n",
    "        train_idx.append(i)\n",
    "        train_loss.append(best_train)\n",
    "    rel_diff = (best_val - total_val_losses[i])\n",
    "    rel_diff /= best_val\n",
    "    if rel_diff > rel_save_thresh:\n",
    "        best_val = total_val_losses[i]\n",
    "        val_idx.append(i)\n",
    "        val_loss.append(best_val)\n",
    "idx = np.argmin(val_loss)\n",
    "\n",
    "# plot errors and improvements\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(total_train_losses, 'b')\n",
    "plt.plot(total_val_losses, 'r')\n",
    "plt.plot(val_idx[idx], val_loss[idx], 'ko')\n",
    "plt.legend([r'Train error', r'Val error', 'Best model'])\n",
    "plt.xlabel(r'Epochs')\n",
    "plt.ylabel(r'Total Loss')\n",
    "plt.title(r'Convergence')\n",
    "plt.grid()\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(train_idx, train_loss, 'b.-')\n",
    "plt.plot(val_idx, val_loss, 'r.-')\n",
    "plt.legend([r'Train error', r'Val error'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(r'Total Loss')\n",
    "plt.title(r'Improvements')\n",
    "plt.grid()\n",
    "plt.tight_layout(h_pad=2, w_pad=2)\n",
    "plt.show()\n",
    "\n",
    "# plot log-scaled errors and improvements\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.semilogy(total_train_losses, 'b')\n",
    "plt.semilogy(total_val_losses, 'r')\n",
    "plt.semilogy(val_idx[idx], val_loss[idx], 'ko')\n",
    "plt.legend([r'Train error', r'Val error', 'Best model'])\n",
    "plt.xlabel(r'Epochs')\n",
    "plt.ylabel(r'Total Loss')\n",
    "plt.title(r'Log Convergence')\n",
    "plt.grid()\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.semilogy(train_idx, train_loss, 'b.-')\n",
    "plt.semilogy(val_idx, val_loss, 'r.-')\n",
    "plt.legend([r'Train error', r'Val error'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel(r'Total Loss')\n",
    "plt.title(r'Log Improvements')\n",
    "plt.grid()\n",
    "plt.tight_layout(h_pad=2, w_pad=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model weights\n",
    "model.load_best_val(device=device)\n",
    "\n",
    "# plot example inputs/outputs/predictions\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "for i in range(64):\n",
    "    \n",
    "    # predict on random validation tile\n",
    "    rand_idx = np.random.choice(len(val_dataset))\n",
    "    tile, true = val_dataset[rand_idx]\n",
    "    pred = model.predict(tile[None].to(device))[0]\n",
    "    tile = val_dataset.image2numpy(tile)\n",
    "    true = val_dataset.mask2numpy(true)\n",
    "    pred = val_dataset.mask2numpy(pred) > 0.5\n",
    "    true[0], true[-1], true[:,0], true[:,-1] = 0, 0, 0, 0\n",
    "    pred[0], pred[-1], pred[:,0], pred[:,-1] = 0, 0, 0, 0\n",
    "\n",
    "    # plot tile, ground truth, and prediction\n",
    "    ax = fig.add_subplot(8, 8, i+1)\n",
    "    plt.imshow(tile, aspect='auto')\n",
    "    if true.sum() > 0:\n",
    "        contour = measure.find_contours(true, 0.5)[0]\n",
    "        ax.plot(contour[:, 1], contour[:, 0], '-', linewidth=2, color='r')\n",
    "    if pred.sum() > 0:\n",
    "        contour = measure.find_contours(pred, 0.5)[0]\n",
    "        ax.plot(contour[:, 1], contour[:, 0], '--', linewidth=2, color='g')\n",
    "    plt.axis('off')\n",
    "    plt.xlim([0, window_size])\n",
    "    plt.ylim([0, window_size])\n",
    "    \n",
    "plt.tight_layout(pad=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# options\n",
    "image_path = '../data/images/'\n",
    "pred_path = '../data/leaf_unet_preds/'\n",
    "image_extension = 'jpeg'\n",
    "pred_extension = 'png'\n",
    "max_number = 10 # number of images to segment, set to None for all images\n",
    "verbose = True\n",
    "save = False\n",
    "show = True\n",
    "fig_size = 15\n",
    "\n",
    "# book keeping\n",
    "w = int(window_size/2)\n",
    "\n",
    "# get image paths\n",
    "image_names = [os.path.basename(f) for f in glob.glob(image_path + '*' + image_extension)]\n",
    "image_names.sort()\n",
    "\n",
    "# load model weights\n",
    "model.load_best_val(device=device)\n",
    "\n",
    "# loop over all leaf images\n",
    "for image_idx, image_name in enumerate(tqdm(image_names)):\n",
    "    \n",
    "    # don't exceed maximum\n",
    "    if max_number is not None:\n",
    "        if image_idx >= max_number:\n",
    "            break\n",
    "            \n",
    "    # load image\n",
    "    if verbose:\n",
    "        print(f'Loading {image_name}...')\n",
    "    image = np.array(Image.open(image_path + image_name)) / 255\n",
    "    \n",
    "    # start timer\n",
    "    t0 = time.time()\n",
    "\n",
    "    # pad image\n",
    "    image = np.pad(image, ((w, w), (w, w), (0, 0)), 'constant', constant_values=1)\n",
    "\n",
    "    # initialize mask\n",
    "    mask = np.zeros_like(image[:, :, 0])\n",
    "    counts = np.zeros_like(image[:, :, 0])\n",
    "\n",
    "    # loop through image in window_size / 2 steps\n",
    "    for i in range(w, image.shape[0] - w, w):\n",
    "        for j in range(w, image.shape[1] - w, w):\n",
    "\n",
    "            # get window\n",
    "            tile = image[i-w:i+w, j-w:j+w, :]\n",
    "            tile = torch.from_numpy(tile).permute(2, 0, 1).float().to(device)\n",
    "\n",
    "            # predict\n",
    "            pred = model.predict(tile[None])[0]\n",
    "            pred = pred.cpu().detach().numpy()[0] > 0.5\n",
    "            pred = pred.astype(float)\n",
    "\n",
    "            # add to mask\n",
    "            mask[i-w:i+w, j-w:j+w] += pred\n",
    "            counts[i-w:i+w, j-w:j+w] += 1\n",
    "\n",
    "    # average mask\n",
    "    mask /= counts.clip(min=1)\n",
    "\n",
    "    # dilate and erode mask to fill gaps\n",
    "    mask = ndimage.binary_dilation(mask.astype(bool), iterations=1)\n",
    "    mask = ndimage.binary_erosion(mask, iterations=1)\n",
    "\n",
    "    # choose largest connected component\n",
    "    mask = measure.label(mask)\n",
    "    mask = mask == np.argmax(np.bincount(mask.flat)[1:]) + 1\n",
    "\n",
    "    # end timer\n",
    "    t1 = time.time()\n",
    "    if verbose:\n",
    "        print(f'Finished in {t1-t0:.2f} seconds.')\n",
    "\n",
    "    # remove padding\n",
    "    image = image[w:-w, w:-w, :]\n",
    "    mask = mask[w:-w, w:-w]\n",
    "\n",
    "    # save mask\n",
    "    if save:\n",
    "        if verbose: \n",
    "            print('Saving mask...')\n",
    "        save_mask = np.concatenate([mask[:,:,None], mask[:,:,None], mask[:,:,None]], axis=-1)\n",
    "        pil_mask = Image.fromarray(np.uint8(255*save_mask))\n",
    "        name = pred_path + image_name.replace(image_extension, pred_extension)\n",
    "        pil_mask.save(name, quality=100, subsampling=0)\n",
    "\n",
    "    # plot overlay\n",
    "    if show:\n",
    "        if max_number is None and image_idx % 100 != 0:\n",
    "            continue\n",
    "        if verbose: \n",
    "            print('Plotting overlay...')\n",
    "        contour = measure.find_contours(mask, 0.5)[0] # [N, 2]\n",
    "        fig = plt.figure(figsize=(image.shape[1]/image.shape[0]*fig_size, fig_size))\n",
    "        plt.imshow(image)\n",
    "        plt.plot(contour[:,1], contour[:,0], 'r-')\n",
    "        plt.show()\n",
    "        \n",
    "    if verbose: \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
